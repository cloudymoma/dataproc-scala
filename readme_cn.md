# âš¡ Spark on Dataproc

[![CI](https://github.com/cloudymoma/dataproc-scala/actions/workflows/ci.yml/badge.svg)](https://github.com/cloudymoma/dataproc-scala/actions/workflows/ci.yml)

ä¸€ä¸ªç”¨äºåœ¨ Google Cloud Dataproc ä¸Šè¿è¡Œ Apache Spark ä½œä¸šçš„ç»¼åˆå·¥å…·åŒ…ï¼Œæ”¯æŒé—ªç”µå¼•æ“ (Lightning Engine) å’ŒåŸç”ŸæŸ¥è¯¢å¼•æ“ (Native Query Engine, NQE)ã€‚

## ğŸ“ æ–‡ä»¶ç”Ÿæˆå™¨ï¼ˆå¯é€‰ï¼‰

ä½¿ç”¨ [CSV æ–‡ä»¶ç”Ÿæˆå™¨](https://github.com/cloudymoma/csv_data_generator) æ¥ç”Ÿæˆå¤§å‹æ–‡ä»¶ã€‚[filegen.py](filegen.py) ç¨å¾®æœ‰äº›æ…¢ã€‚

## ğŸ› ï¸ Make å‘½ä»¤

### ğŸ—ï¸ åŸºç¡€è®¾æ–½è®¾ç½®
- **`make histserver`** - åˆ›å»º [æŒä¹…åŒ–å†å²æœåŠ¡å™¨ (PHS)](https://cloud.google.com/dataproc/docs/concepts/jobs/history-server)
- **`make jobserver`** - åˆ›å»ºå…·æœ‰è®¡ç®—èµ„æºè‡ªåŠ¨ç¼©æ”¾çš„ä¸´æ—¶ä½œä¸šæœåŠ¡å™¨ï¼Œå¯é€šè¿‡ [autoscaling-policy.yml](autoscaling-policy.yml) é…ç½®ã€‚å¯ä»¥å…³é—­ã€‚

### ğŸ”¨ æ„å»ºå’Œè¿è¡Œ
- **`make build`** - æ„å»º Scala æºä»£ç 
- **`make run`** - åœ¨ä¸´æ—¶é›†ç¾¤ä¸Šè¿è¡Œä½œä¸šï¼ˆé«˜åº¦å¯å®šåˆ¶ï¼‰
  - æ”¯æŒ [é—ªç”µå¼•æ“](https://cloud.google.com/blog/products/data-analytics/introducing-lightning-engine-for-apache-spark?e=48754805) å’ŒåŸç”ŸæŸ¥è¯¢å¼•æ“

### â˜ï¸ æ— æœåŠ¡å™¨æ‰§è¡Œ
- **`make run_serverless`** - åœ¨ Dataproc æ— æœåŠ¡å™¨ **é«˜çº§** æ¨¡å¼ä¸‹è¿è¡Œæ‰¹å¤„ç†ä½œä¸š
  - ä½¿ç”¨ N2 å®ä¾‹ + LocalSSD shuffle
- **`make run_serverless_std`** - åœ¨ Dataproc æ— æœåŠ¡å™¨ **æ ‡å‡†** æ¨¡å¼ä¸‹è¿è¡Œæ‰¹å¤„ç†ä½œä¸š
  - ä½¿ç”¨ E2 å®ä¾‹ + pd-standard shuffle
- **`make run_nqe`** - å¯ç”¨åŸç”ŸæŸ¥è¯¢å¼•æ“è¿è¡Œ
  - ä½¿ç”¨ N2 + LocalSSD shuffle + åŸç”Ÿæ‰§è¡Œå¼•æ“
  - éœ€è¦ä½¿ç”¨ `make qualify` è¿›è¡Œå…¼å®¹æ€§æ£€æŸ¥

### âœ… ä½œä¸šå…¼å®¹æ€§
- **`make qualify`** - é’ˆå¯¹ Spark äº‹ä»¶æ—¥å¿—è¿è¡Œèµ„æ ¼éªŒè¯å·¥å…·ï¼Œæ£€æŸ¥ **`NQE`** çš„ä½œä¸šå…¼å®¹æ€§

## âš™ï¸ é…ç½®

### ğŸ›ï¸ Dataproc é›†ç¾¤å±‚çº§è®¾ç½®
```bash
# Default tier (standard)
export DATAPROC_TIER=standard

# Premium tier (Lightning Engine)
export DATAPROC_TIER=premium

# Enable Native Query Engine (Premium tier only)
export ENABLE_NQE=true
```

> **æ³¨æ„ï¼š** åŸç”ŸæŸ¥è¯¢å¼•æ“ä»…åœ¨é«˜çº§å±‚çº§é›†ç¾¤ä¸Šå¯ç”¨ã€‚

### ğŸ“ ä½œä¸šé…ç½®
åœ¨ [`spark.sh`](spark.sh) ä¸­æ‰‹åŠ¨è°ƒæ•´ä½œä¸šé…ç½®ä»¥é€‚åº”æ‚¨çš„ç‰¹å®šéœ€æ±‚ã€‚ä½¿ç”¨ NQE æ—¶ï¼Œå§‹ç»ˆå…ˆè¿è¡Œèµ„æ ¼éªŒè¯å·¥å…·ä»¥ç¡®ä¿å…¼å®¹æ€§ã€‚

## ğŸ“š é™„åŠ èµ„æº

- **BigQuery é›†æˆï¼š** åœ¨ [BigQuery](https://cloud.google.com/bigquery) ä¸­ä»¥å­˜å‚¨è¿‡ç¨‹å½¢å¼è¿è¡Œ [Spark æ— æœåŠ¡å™¨](https://cloud.google.com/products/serverless-spark) - [æŒ‡å—](https://github.com/cloudymoma/gcp-playgroud-public/blob/master/BigQuery/bq_spark.md)

## ğŸ”¬ FIOï¼ˆçµæ´» I/O æµ‹è¯•å™¨ï¼‰é›†æˆ

### ğŸ”§ ä»æºç æ„å»º FIO

#### ğŸ—ï¸ åŸºæœ¬æ„å»º
```bash
git clone https://github.com/axboe/fio.git
cd fio
./configure --build-static
make
```

#### ğŸ”§ æ„å»ºæ•…éšœæ’é™¤

**é’ˆå¯¹è™šæ‹ŸåŒ–ç¯å¢ƒ (QEMU)ï¼š**
```bash
./configure --build-static --disable-optimizations
```

**æœ€å°è½»é‡åŒ–é…ç½®ï¼š**
```bash
./configure --build-static \
    --disable-numa \
    --disable-rdma \
    --disable-gfapi \
    --disable-libhdfs \
    --disable-pmem \
    --disable-gfio \
    --disable-libiscsi \
    --disable-rados \
    --disable-rbd \
    --disable-zlib
```

è¿è¡Œ `make` åï¼Œ`fio` äºŒè¿›åˆ¶æ–‡ä»¶å°†åœ¨æ‚¨çš„é¡¹ç›®ç›®å½•ä¸­å¯ç”¨ã€‚

#### ğŸš€ éƒ¨ç½²åˆ° GCS
```bash
gcloud storage cp fio gs://dingoproc/fio_linux_x86
```

æŸ¥çœ‹ [GcpTest.scala#L277-L295](https://github.com/cloudymoma/dataproc-scala/blob/main/src/main/scala/GcpTest.scala#L277-L295) äº†è§£è¿è¡Œæ—¶ä¸‹è½½åˆ° Spark workers çš„æ–¹æ³•ã€‚

### ğŸ“Š FIO æ€§èƒ½æµ‹è¯•é€ŸæŸ¥è¡¨

#### ğŸ”¨ åŸºæœ¬æµ‹è¯•

**éšæœºè¯»å–æµ‹è¯•**
```bash
fio --name=randread --ioengine=libaio --iodepth=16 --rw=randread --bs=4k --direct=0 --size=512M --numjobs=4 --runtime=240 --group_reporting
```

**éšæœºå†™å…¥æµ‹è¯•** (æ€»è®¡ 2GBï¼š4 ä¸ªä½œä¸š Ã— 512MB)
```bash
fio --name=randwrite --ioengine=libaio --iodepth=1 --rw=randwrite --bs=4k --direct=0 --size=512M --numjobs=4 --runtime=240 --group_reporting
```

**æ··åˆè¯»å†™æµ‹è¯•** (75% è¯»å–ï¼Œ25% å†™å…¥)
```bash
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=random_read_write.fio --bs=4k --iodepth=64 --size=4G --readwrite=randrw --rwmixread=75
```

#### â© é¡ºåºæ€§èƒ½æµ‹è¯•

**é¡ºåºè¯»å–** (8K å—ï¼Œç›´æ¥ I/O)
```bash
fio --name=seqread --rw=read --direct=1 --ioengine=libaio --bs=8k --numjobs=8 --size=1G --runtime=600 --group_reporting
```

**é¡ºåºå†™å…¥** (32K å—ï¼Œç›´æ¥ I/O)
```bash
fio --name=seqwrite --rw=write --direct=1 --ioengine=libaio --bs=32k --numjobs=4 --size=2G --runtime=600 --group_reporting
```

#### ğŸ² éšæœºæ€§èƒ½æµ‹è¯•

**éšæœºè¯»å–** (8K å—ï¼Œç›´æ¥ I/O)
```bash
fio --name=randread --rw=randread --direct=1 --ioengine=libaio --bs=8k --numjobs=16 --size=1G --runtime=600 --group_reporting
```

**éšæœºå†™å…¥** (64K å—ï¼Œç›´æ¥ I/O)
```bash
fio --name=randwrite --rw=randwrite --direct=1 --ioengine=libaio --bs=64k --numjobs=8 --size=512m --runtime=600 --group_reporting
```

**æ··åˆéšæœºè¯»å†™** (90% è¯»å–ï¼Œ10% å†™å…¥)
```bash
fio --name=randrw --rw=randrw --direct=1 --ioengine=libaio --bs=16k --numjobs=8 --rwmixread=90 --size=1G --runtime=600 --group_reporting
```

#### ğŸš€ é«˜çº§æµ‹è¯•åœºæ™¯

**åŸºäºæ—¶é—´çš„æ··åˆå·¥ä½œè´Ÿè½½** (70% è¯»å–ï¼Œ30% å†™å…¥ï¼Œ5 åˆ†é’ŸæŒç»­æ—¶é—´)
- åˆ›å»º 8 ä¸ªæ–‡ä»¶ï¼ˆæ¯ä¸ª 512MBï¼‰ï¼Œä½¿ç”¨ 64K å—å¤§å°
- æ— è®ºæ˜¯å¦å®Œæˆéƒ½ç²¾ç¡®è¿è¡Œ 5 åˆ†é’Ÿ
```bash
fio --name=randrw --ioengine=libaio --iodepth=1 --rw=randrw --bs=64k --direct=1 --size=512m --numjobs=8 --runtime=300 --group_reporting --time_based --rwmixread=70
```

**æ•°æ®åº“æ¨¡æ‹Ÿ** (3:1 è¯»å†™æ¯”ä¾‹ï¼Œå…¸å‹æ•°æ®åº“å·¥ä½œè´Ÿè½½)
- 4GB æ–‡ä»¶ï¼Œ4KB æ“ä½œ
- 75% è¯»å–ï¼Œ25% å†™å…¥åˆ†å‰²
- 64 ä¸ªå¹¶å‘æ“ä½œ
```bash
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=randrw --rwmixread=75
```

**çº¯éšæœºè¯»å–æ€§èƒ½**
```bash
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=randread
```

**çº¯éšæœºå†™å…¥æ€§èƒ½**
```bash
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=randwrite
```